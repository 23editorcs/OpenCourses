{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0, dtype=tf.float32)\n",
    "node2 = tf.constant(4.0, dtype=tf.float32)\n",
    "\n",
    "print(node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run([node1, node2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node3 = tf.add(node1, node2)\n",
    "\n",
    "print(\"node3:\", node3)\n",
    "print(\"sess.run(node3):\", sess.run(node3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = tf.add(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(adder_node, feed_dict={a: 3, b: 4.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(adder_node, feed_dict={a: [1, 2], b: [3, 4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(linear_model, feed_dict={x: [1, 2, 3, 4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print(sess.run(loss, feed_dict={x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixW = tf.assign(W, [-1.])\n",
    "fixb = tf.assign(b, [1.])\n",
    "sess.run([fixW, fixb])\n",
    "print(sess.run(loss, feed_dict={x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)\n",
    "for i in range(1000):\n",
    "    sess.run(train, feed_dict={x: [1, 2, 3, 4], y: [0, -1, -2, -3]})\n",
    "    \n",
    "print(sess.run([W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "\n",
    "# Training inputs x, y\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# loss \n",
    "loss = tf.reduce_sum(tf.square(linear_model - y)) \n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# training data\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "\n",
    "# init all variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init) # reset values to wrong\n",
    "\n",
    "# training loop\n",
    "for i in range(1000):\n",
    "    sess.run(train, feed_dict={x: x_train, y: y_train})\n",
    "\n",
    "# evaluate training accuracy\n",
    "curr_W, curr_b, curr_loss = sess.run([W, b, loss], feed_dict={x: x_train, y: y_train})\n",
    "print(\"W: \" + str(curr_W) + \" b: \" + str(curr_b) + \" loss: \" + str(curr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Tosiba\\AppData\\Local\\Temp\\tmpq_f0ccz3\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Tosiba\\\\AppData\\\\Local\\\\Temp\\\\tmpq_f0ccz3', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Tosiba\\AppData\\Local\\Temp\\tmpq_f0ccz3\\model.ckpt.\n",
      "INFO:tensorflow:loss = 18.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1421.77\n",
      "INFO:tensorflow:loss = 0.509219, step = 101 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1119.46\n",
      "INFO:tensorflow:loss = 0.0537287, step = 201 (0.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 1285.25\n",
      "INFO:tensorflow:loss = 0.022815, step = 301 (0.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 1186.84\n",
      "INFO:tensorflow:loss = 0.00333666, step = 401 (0.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 1538.08\n",
      "INFO:tensorflow:loss = 0.00183311, step = 501 (0.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 1376.11\n",
      "INFO:tensorflow:loss = 0.000496614, step = 601 (0.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1278.63\n",
      "INFO:tensorflow:loss = 0.000163804, step = 701 (0.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 1534.39\n",
      "INFO:tensorflow:loss = 4.78177e-05, step = 801 (0.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 1583.09\n",
      "INFO:tensorflow:loss = 9.71569e-06, step = 901 (0.063 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\Tosiba\\AppData\\Local\\Temp\\tmpq_f0ccz3\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.223e-06.\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-25-11:30:17\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Tosiba\\AppData\\Local\\Temp\\tmpq_f0ccz3\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-25-11:30:18\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 6.32181e-07, global_step = 1000, loss = 2.52873e-06\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-25-11:30:18\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Tosiba\\AppData\\Local\\Temp\\tmpq_f0ccz3\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-25-11:30:18\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 0.0025967, global_step = 1000, loss = 0.0103868\n",
      "train metrics: {'average_loss': 6.3218141e-07, 'loss': 2.5287256e-06, 'global_step': 1000}\n",
      "eval metrics: {'average_loss': 0.0025966973, 'loss': 0.010386789, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Use estimator\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Declare list of features \n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]\n",
    "\n",
    "# Set up an estimator that does Linear Regression\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
    "\n",
    "# Set up the data sets\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "\n",
    "# Shuffle the input train set with the batch_size\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn({\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "\n",
    "# Separate the input train set to num_epochs \n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn({\"x\": x_train}, y_train, batch_size=4, num_epochs=1, shuffle=False)\n",
    "\n",
    "# set up the evaluate data set\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn({\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1, shuffle=False)\n",
    "\n",
    "# Training 1000 steps\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "\n",
    "# Evaluate how well our model did\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
